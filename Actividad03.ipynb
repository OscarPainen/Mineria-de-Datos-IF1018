{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.datasets import load_diabetes, load_breast_cancer, load_digits\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test, name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n{name} sin GridSearch:\")\n",
    "    print(f\"Precisión: {accuracy:.4f}\")\n",
    "    print(\"Reporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "def grid_search_and_evaluate(model, param_grid, X_train, X_test, y_train, y_test, name):\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n{name} con GridSearch:\")\n",
    "    print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "    print(f\"Precisión: {accuracy:.4f}\")\n",
    "    print(\"Reporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Random Forest con el dataset de Diabetes\n",
    "print(\"Random Forest - Dataset de Diabetes\")\n",
    "diabetes = load_diabetes()\n",
    "X, y = diabetes.data, diabetes.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "train_and_evaluate(rf, X_train, X_test, y_train, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "best_rf = grid_search_and_evaluate(rf, param_grid_rf, X_train, X_test, y_train, y_test, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Decision Tree con el dataset de Cáncer de Mama\n",
    "print(\"\\nDecision Tree - Dataset de Cáncer de Mama\")\n",
    "breast_cancer = load_breast_cancer()\n",
    "X, y = breast_cancer.data, breast_cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "train_and_evaluate(dt, X_train, X_test, y_train, y_test, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_dt = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "best_dt = grid_search_and_evaluate(dt, param_grid_dt, X_train, X_test, y_train, y_test, \"Decision Tree\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Naive Bayes con el dataset de Dígitos\n",
    "print(\"\\nNaive Bayes - Dataset de Dígitos\")\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "nb = GaussianNB()\n",
    "train_and_evaluate(nb, X_train, X_test, y_train, y_test, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_nb = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "best_nb = grid_search_and_evaluate(nb, param_grid_nb, X_train, X_test, y_train, y_test, \"Naive Bayes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nActividad 1: Experimentación con diferentes conjuntos de datos\")\n",
    "print(\"1. Utilice los modelos entrenados (best_rf, best_dt, best_nb) con un conjunto de datos diferente.\")\n",
    "print(\"2. Compare el rendimiento de los modelos en el nuevo conjunto de datos.\")\n",
    "print(\"3. Discuta por qué el rendimiento puede variar entre diferentes conjuntos de datos.\")\n",
    "\n",
    "# Actividad 2: Ajuste manual de hiperparámetros\n",
    "print(\"\\nActividad 2: Ajuste manual de hiperparámetros\")\n",
    "print(\"1. Elija uno de los modelos (Random Forest, Decision Tree o Naive Bayes).\")\n",
    "print(\"2. Ajuste manualmente los hiperparámetros basándose en su comprensión del modelo.\")\n",
    "print(\"3. Compare el rendimiento de su modelo ajustado manualmente con el mejor modelo encontrado por GridSearch.\")\n",
    "print(\"4. Discuta las ventajas y desventajas del ajuste manual vs. GridSearch.\")\n",
    "\n",
    "# Actividad 3: Interpretación de resultados\n",
    "print(\"\\nActividad 3: Interpretación de resultados\")\n",
    "print(\"1. Para cada modelo, analice el reporte de clasificación (precisión, recall, f1-score).\")\n",
    "print(\"2. Discuta qué métricas son más importantes según el contexto del problema (diabetes, cáncer de mama, reconocimiento de dígitos).\")\n",
    "print(\"3. Proponga posibles mejoras para cada modelo basándose en los resultados obtenidos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actividad 1: Visualización de la importancia de características\n",
    "def plot_feature_importance(model, feature_names, title):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(title)\n",
    "    plt.bar(range(10), importances[indices][:10])\n",
    "    plt.xticks(range(10), [feature_names[i] for i in indices[:10]], rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nActividad 1: Visualización de la importancia de características\")\n",
    "print(\"Ejecute la siguiente función para Random Forest y Decision Tree:\")\n",
    "print(\"plot_feature_importance(best_rf, diabetes.feature_names, 'Importancia de características - Random Forest')\")\n",
    "print(\"plot_feature_importance(best_dt, breast_cancer.feature_names, 'Importancia de características - Decision Tree')\")\n",
    "\n",
    "# Actividad 2: Comparación de curvas de aprendizaje\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, X, y, title):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=5, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
    "    plt.ylabel(\"Puntuación\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Puntuación de entrenamiento\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Puntuación de validación cruzada\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nActividad 2: Comparación de curvas de aprendizaje\")\n",
    "print(\"Ejecute la siguiente función para cada modelo:\")\n",
    "print(\"plot_learning_curve(best_rf, X, y, 'Curva de Aprendizaje - Random Forest')\")\n",
    "print(\"plot_learning_curve(best_dt, X, y, 'Curva de Aprendizaje - Decision Tree')\")\n",
    "print(\"plot_learning_curve(best_nb, X, y, 'Curva de Aprendizaje - Naive Bayes')\")\n",
    "\n",
    "# Actividad 3: Experimentación con diferentes conjuntos de datos\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
